#! /usr/bin/env python3

from bs4 import BeautifulSoup
import requests
import re
import os

BASE_URL = "https://www.vulnhub.com"
PAGE_QUERY = BASE_URL + "/?page=" 

class MachineInfo():
    #TODO

    pass

class VulnHubMachine():
    # TODO
    pass

def get_pages():
    result = list()
    req = requests.get(BASE_URL)
    soup = BeautifulSoup(req.text,features="lxml")

    list_div = soup.findAll("div", {"class": "text-center pagination"})
    for d in list_div:
        pages = d.findAll("a", href=re.compile("page"), text=re.compile("[0-9]+"))
    for p in pages:
        result.append(PAGE_QUERY + p.text)
    return result

def get_info(req):
    info = ""
    soup = BeautifulSoup(req.text,features="lxml")
    info_div = soup.find("div", {"class": "accordion-inner"})
    #TODO
    print(info_div)


    
    return info


def get_machine(entry_url):
    MACHINE_URL = BASE_URL + entry_url
    result = ""
    req = requests.get(MACHINE_URL)
    info = get_info(req)

    return result




def get_machines_per_page(page):
    result = list()
    req = requests.get(page)
    soup = BeautifulSoup(req.text,features="lxml")

    list_div = soup.findAll("div", {"class": "span12 entry"})
    for d in list_div:
        entry_url = d.find("div", {"class": "span9 entry-title"}).find("a").attrs['href'] 
        result.append(get_machine(entry_url))
        # TODO remove below
        break
    return result




pages = get_pages()

for p in pages:
    get_machines_per_page(p)
    # TODO remove below
    break
